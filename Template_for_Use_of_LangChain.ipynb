{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1319414d-f48b-426c-aed8-2aaae0b2c1c2",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3391ed0c-0ba6-439c-93a2-56256e18bb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of langchain Prompt Template and Chain\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "# Import llm to be able to interact with GPT4All directly from langchain\n",
    "from langchain.llms import GPT4All\n",
    "# Callbacks manager is required for the response handling \n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce7645b-a5b5-466d-bd9a-2bfc66e21d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = './models/gpt4all-converted.bin' \n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b119cd-0d4a-4da1-97e0-30b9652a7346",
   "metadata": {},
   "source": [
    "# 1. Template for Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac621b4b-ec5a-4e0e-89ad-0dc560a1cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step on it.\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# initialize the GPT4All instance\n",
    "llm = GPT4All(model=local_path, callback_manager=callback_manager, verbose=True)\n",
    "# link the language model with our prompt template\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb5645-5ae0-4d3d-8089-9cb610231db8",
   "metadata": {},
   "source": [
    "# 2. Template for Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4656538-fb13-479b-a330-47df0c3f4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoded question\n",
    "question = \"Can you describe how GPT4All works?\"\n",
    "\n",
    "# User imput question...\n",
    "# question = input(\"Enter your question: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14136a18-7195-41bf-be99-4e225e20d4ca",
   "metadata": {},
   "source": [
    "# 3. Execution of LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2674713a-32a7-4c7b-8e1b-3eac3e0f0f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: Can you describe how GPT4All works?\n",
      "\n",
      "Answer: Let's think step by step on it.\n",
      "\n",
      "1 - The idea behind this project is to collect publicly available datasets, train models using those data sets and release the trained model as an open-source library (i.e., a Python package). So far, GPT4All has collected more than 25 million sentences from many sources such as books like \"Little Women\" or Wikipedia articles in different languages to name just some of them.\n",
      "\n",
      "   Once enough data is gathered and processed through the model training algorithm that we use (i.e., the pre-trained language models), then GPT4All will release its trained NLP models which are open source for anyone who wants to use it, study or improve upon their functionality/capabilities! \n",
      "\n",
      "2 - These datasets can be used by individuals and companies alike in numerous ways such as natural language processing (NLP) tasks like text classification, sentiment analysis, summarization or generation of abstractive content. Additionally, the project aims to facilitate research into NLG systems that could further improve automated writing skills among others!\n",
      "   In essence, GPT4All is an open-source community effort aiming at improving on Natural Language Processing (NLP) models for building text generation tools based"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Question: Can you describe how GPT4All works?\\n\\nAnswer: Let\\'s think step by step on it.\\n\\n1 - The idea behind this project is to collect publicly available datasets, train models using those data sets and release the trained model as an open-source library (i.e., a Python package). So far, GPT4All has collected more than 25 million sentences from many sources such as books like \"Little Women\" or Wikipedia articles in different languages to name just some of them.\\n\\n   Once enough data is gathered and processed through the model training algorithm that we use (i.e., the pre-trained language models), then GPT4All will release its trained NLP models which are open source for anyone who wants to use it, study or improve upon their functionality/capabilities! \\n\\n2 - These datasets can be used by individuals and companies alike in numerous ways such as natural language processing (NLP) tasks like text classification, sentiment analysis, summarization or generation of abstractive content. Additionally, the project aims to facilitate research into NLG systems that could further improve automated writing skills among others!\\n   In essence, GPT4All is an open-source community effort aiming at improving on Natural Language Processing (NLP) models for building text generation tools based'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the query and get the results\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb195553-3340-44a6-acdb-a8810d0dc11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpt4all]",
   "language": "python",
   "name": "conda-env-gpt4all-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
